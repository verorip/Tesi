\chapter{Applicazioni per il MM}

\section{Modulo per comandi vocali}
La prima applicazione implementata, come è stato accennato nell'introduzione, è
stata il controllo del Magic Mirror tramite comandi vocali.
Nello specifico l'applicazione doveva, tramite delle specifiche frasi,
gestire le altre applicazioni presenti nel Magic Mirror.\\
Il compito di trasformare da parlato a testo scritto e l'elaborazione delle frasi è stato
lasciato a carico di Google Speech API.
Prima di spiegare il codice ci sono alcune dipendenze da spiegare.

\subsection{Sound eXchange (SoX)}
Per permettere al microfono di catturare ed elaborare correttamente l'audio nell'ambiente
Raspbian è necessario installare Sound eXchange (SoX), un software per la manipolazione
dell'audio, utile per effettuare uno streaming dell'audio.
Per installarlo correttamente è necessario avere il Sistema Operativo aggiornato,
usando il seguente comando da Shell:
\begin{lstlisting}[language=bash]
  $ sudo apt-get update
\end{lstlisting}
Il comando \textit{sudo} è un controllo speciale che permette di eseguire i comandi in modalità
Super User, un utente speciale che ha i privilegi di amministrazione all'interno del sistema.
\textit{apt-get} è uno strumento da riga di comando che permette di usare l'APT (Advanced Packaging Tool),
un gestore di pacchetti dei sistemi Debian.
Il parametro \textit{get} indica l'operazione da eseguire con \textit{apt}, in questo caso scaricare
un pacchetto.
\textit{update} indica l'obbiettivo di cercare aggiornamenti del S.O.
Una volta completato si può installare il software sempre tramite comando da Shell:
\begin{lstlisting}[language=bash]
  $ sudo apt-get install sox
\end{lstlisting}
Il parametro \textit{install} serve ad indicare di installare il pacchetot oltre a scaricarlo, mentre \textit{sox}
è il nome del pacchetto che si vuole cercare.
Al termine del processo è necessario collegare il driver audio di Raspbian ALSA (Advanced Linux Sound Architecture)
a SoX e indicare a quest'ultimo a quale periferica interfacciarsi, tramite i comandi:
\begin{lstlisting}[language=bash]
  $ export AUDIODEV=hw:1,0
  $ export AUDIODRIVER=alsa
\end{lstlisting}
\textit{export} è un comando Linux usato per assegnare valori a Variabili d'Ambiente.
\textit{AUDIODEV} è la variabile d'ambiente che identifica il dispositivo audio di Default, mentre
\textit{hw:1,0} indica l'assegnamento della periferica 0 presente sulla scheda 1.
il comando \textit{export AUDIODRIVER=alsa} è opzionale, perchè assegna alla variabile d'ambiente
\textit{AUDIODRIVER}, la varibiale che fa riferiemnto al driver audio del sistema, ALSA,
il quale dovrebbe essere già quello predefinito.

\subsection{Autenticazione Google API}
Per poter usufruire dell'API di Google è necessario fornire un'autenticazione a livello
di sistema.
Per poterlo fare è necessario ottenere delle credenziali di sicurezza per un account Google,
attivabili tramite Google Cloud Platform Console.
Le credenziali consistono in un username, la mail dell'account google, e una chiave di sicurezza unica,
entrambi sono contenuti in un file JSON che può essere scaricato e salvato in locale.
Per poter permettere al sistema di utilizzare l'API bisogna fare in modo che le credenziali siano
raggiungibili, inserendole in una Variabile d'Ambiente con il comando:
\begin{lstlisting}[language=bash]
  $ export GOOGLE_APPLICATION_CREDENTIALS='Percorso del JSON'
\end{lstlisting}

\subsection{Node Heloer dell'applicazione}
Il node Helper dell'applicazione si occupa di gestire lo streaming con L'API e
di mandare i risultati (o gli errori) all'applicazione tramite le funzioni messe
a disposizione dal Magic Mirror mostrate precedentemente.

\begin{lstlisting}[language=Javascript]
  var NodeHelper = require("node_helper");
  const record = require('node-record-lpcm16');
  const Speech = require('@google-cloud/speech');
  const speech = Speech();
  const request = {
    config: {
      encoding: encoding /*(Es. LINEAR16)*/,
      sampleRateHertz: sampleRateHertz /*(Es. 16000)*/,
      languageCode: languageCode /*(Es. it-IT)*/
    },
    interimResults: false /*usato se si vuole conoscere l'output prima dell'elaborazione*/
  };

module.exports = NodeHelper.create({
  start: function () {
        console.log("Starting Node Helper of module: " +this.name);
    },

    socketNotificationReceived: function(notification, payload) {
        var self = this;
        if (notification === "ready") {
            listen();
        }
    },

    listen: function(){
      // Create a recognize stream
      const recognizeStream = speech.streamingRecognize(request)
        .on('error', sendSocketNotification("recognizerror"))
        .on('data', (data) =>
          if(Transcription: ${data.results[0].alternatives[0].transcript}\n)
            sendSocketNotification('limit_reached')
          else
            sendSocketNotification('response', data.results[0])

      // Start recording and send the microphone input to the Speech API
      record
        .start({
          sampleRateHertz: 1600,
          threshold: 0,
          verbose: false,
          recordProgram: 'sox',
          silence: '20.0'
        })
        .on('error', sendSocketNotification('recorderror'))
        .pipe(recognizeStream);
    }
})
\end{lstlisting}
