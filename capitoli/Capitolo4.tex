\chapter{Applicazioni per il MM}\label{capitolo4}
In questo capitolo vengono spiegati i requisiti per i moduli sviluppati durante lo stage e la loro implementazione.

\section{Modulo per comandi vocali}
La prima applicazione implementata, come è stato accennato nell'introduzione, è
stata il controllo del Magic Mirror tramite comandi vocali.
Nello specifico l'applicazione doveva, tramite delle specifiche frasi,
gestire le altre applicazioni presenti nel Magic Mirror.\\
Il compito di trasformare da parlato a testo scritto e l'elaborazione delle frasi è stato
lasciato a carico di Google Speech API.
Per poter implemententare l'API è necessario installare delle dipendenze.

\subsection{Sound eXchange (SoX)}
Per permettere al microfono di catturare ed elaborare correttamente l'audio nell'ambiente
Raspbian è necessario installare Sound eXchange (SoX), un software per la manipolazione
dell'audio, utile per effettuarne lo streaming.
Per installarlo correttamente è necessario avere il Sistema Operativo aggiornato all'ultima versione.
L'installazione di SoX viene eseguita tramite semplice riga di comando usando l'Advanced Packaging Tool (APT),
un gestore di pacchetti dei sistemi Linux e distribuzioni Linux.
Affinchè il microfono si colleghi correttamente al programma è necessario impostare correttamente
i valori delle varibili d'ambiente \textit{AUDIODEV} e \textit{AUDIODRIVER}.
La prima variabile corrisponde alla porta hardware al quale il programma deve fare riferimento,
la seocnda varibile il driver audio da utilizzare, di solito il predefinito è Advanced Linux Sound Architecture(ALSA).

\subsection{Autenticazione Google API}
Per poter usufruire dell'API di Google è necessario fornire un'autenticazione a livello
di sistema.
Per poterlo fare è necessario ottenere delle credenziali di sicurezza per un account Google,
attivabili tramite Google Cloud Platform Console.
Le credenziali consistono in un username, l'email dell'account google, e una chiave di sicurezza unica,
 contenuti in un file JSON che può essere scaricato e salvato in locale.
Per poter permettere al sistema di utilizzare l'API bisogna fare in modo che il file JSOn con le credenziali sia
raggiungibile all'interno del sistema e per farlo bisogna creare una variabile d'ambiente con assegnato il percorso
dove si trova il file.

\subsection{Comunicazione con l'API}
Il node Helper dell'applicazione si occupa di gestire lo streaming con L'API e
di mandare i risultati (o gli errori) all'applicazione tramite le funzioni messe
a disposizione dal Magic Mirror mostrate nella sezione \ref{cap:MMmess}.
Il seguente codice viene usato per creare un canale streeaming con l'API:
\begin{lstlisting}[language=Javascript, caption={Codice per la comunicazione con l'API}, captionpos=b]
      const recognizeStream = speech.streamingRecognize(request)
        .on('error', sendSocketNotification("error"))
        .on('data', (data) =>
          if(Transcription: ${data.results[0].alternatives[0].transcript}\n)
            sendSocketNotification('limit_reached')
          else
            sendSocketNotification('response', data.results[0])
\end{lstlisting}
\emph{speech.streamingRecognize(request)}, richiama la funzione dell'API per aprire una connessione, dove request è
il flusso audio.
La funzione posi si mette in attesa di una risposta dall'API la quale può essere di due tipi:
\begin{itemize}
\item .on('error'), nel caso ci sia stato un errore di connessione, in quel caso viene mandato al modulo un messaggio di errore
\item .on('data') nel caso di risposta senza errori, ma che può essere divisa in altre due risposte. La prima è nel caso in cui
viene raggiunto il limite di parole tradotte (Google mette a disposizione un limite di parole tradotte al giorno gatuitamente), oppure
la stringa contenente la frase tradotta.\\[1\baselineskip]
\end{itemize}
Per passare il flusso audio alla funzione appena descritta bisogna creare una \emph{pipe}, ovvero uno strumento
per permettere a due processi di comunicare.
Il seguente codice:
\begin{lstlisting}[language=Javascript]
      // Start recording and send the microphone input to the Speech API
      record
        .start({
          sampleRateHertz: 1600,
          threshold: 0,
          verbose: false,
          recordProgram: 'sox',
          silence: '20.0'
        })
        .on('error', sendSocketNotification('error'))
        .pipe(recognizeStream);
\end{lstlisting}
imposta tramite il metodo \emph{.start} i settaggi dello streaming (per esempio la frequenza) e fa partire la registrazione.
La funzione \emph{.on('error')} serve per sollevare un'eccezione in caso di errore, che poi viene inoltrata al modulo.
La funzione \emph{.pipe(recognizeStream)} crea una pipe tra la funzione di registrazione e \emph{recognizeStream} descritta nel codice precedente,
passando il flusso audio direttamente alla funzione.

\section{Modulo con Touch Board}
Nell'implementazione del modulo con la Touch Board è necessario aver installato nel sistema
il linguaggio di programmazione Python, descritto nella sezione \ref{cap:python}.\\
La Touch Board si presenta come una scheda con 40 porte I/O, le quali devono essere collegate alle
GPIO della scheda Raspberry e con un sensore elettrico di prossimità, come mostrato in figura , che permette di catturare i movimenti fino a 5cm di distanza.
Le librerie Python in dotazione con la scheda offrono funzioni per catturare i diversi input trasmessi come
la direzione di spostamento del dito, oppure la cattura di un tocco sulla scheda.\\
Per poter eseguire un programma Python sul MM è necessario usare la libreria Javascript \emph{Python-Shell}, la quale
permette di avviare una shell di Python in background e avviare, di conseguenza, i programmi.
La comunicazione tra programma Python e Node-Helper avviene tramite messaggi in JSON, quando la scheda riceve un input
il programma Python esegue una stampa (\emph{print()}) di un JSON contente il risultato, questa stampa viene catturata dal
Node-Helper tramite la funzione \emph{pythonshell.on('message', function (message) \{ ... \})} la quale tramite la funzione di callback
gestisce il corpo del messaggio.

\begin{figure}[H]
    \includegraphics[width=1\textwidth, height=0.6\textheight]{skywriter}
    \caption{Magic Mirror by Michael Teeuw}
    \label{fig:TouchBoard}
\end{figure}
